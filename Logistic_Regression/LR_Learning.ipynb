{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7666846",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4d7b3",
   "metadata": {},
   "source": [
    "### Checking the significance of Vectorization\n",
    "#### Way faster than for loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af425955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for dot product: 1.0700225830078125 ms\n",
      "Dot product result: 2499752.6412505116\n",
      "Time taken for loop dot product: 2561.891794204712 ms\n",
      "Loop dot product result: 2499752.6412503873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Generating 2 vectors of size 10 million and calculating their dot product using numpy\n",
    "# and a for loop to compare performance.\n",
    "a=np.random.rand(10000000)\n",
    "b=np.random.rand(10000000)\n",
    "\n",
    "#Noting Start time and End time to get the time needed to calculate the dot product\n",
    "start=time.time()\n",
    "# Dot product using numpy\n",
    "c=np.dot(a,b)\n",
    "end=time.time()\n",
    "print(\"Time taken for dot product:\", (end-start)*1000, \"ms\")\n",
    "print(\"Dot product result:\", c)\n",
    "\n",
    "# Noting Start time and End time to get the time needed to calculate the dot product using a for loop\n",
    "start=time.time()\n",
    "d=0\n",
    "# For loop dot product\n",
    "for i in range(10000000):\n",
    "    d+=a[i]*b[i]\n",
    "end=time.time()\n",
    "print(\"Time taken for loop dot product:\", (end-start)*1000, \"ms\")\n",
    "print(\"Loop dot product result:\", d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "058f13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for element wise EXPO operations: 390.0773525238037 ms\n",
      "Time taken for element wise ASINE operations: 730.9997081756592 ms\n",
      "Time taken for element wise degree operations: 202.55017280578613 ms\n",
      "total time taken for element wise operations: 1323.627233505249 ms\n"
     ]
    }
   ],
   "source": [
    "# Other Element wise operations usinfg numpy\n",
    "a=np.random.rand(100000000)\n",
    "start=time.time()\n",
    "ae=np.exp(a)\n",
    "end1=time.time()\n",
    "print(\"Time taken for element wise EXPO operations:\", (end1-start)*1000, \"ms\")\n",
    "asine=np.arctan(a)\n",
    "end2=time.time()\n",
    "print(\"Time taken for element wise ASINE operations:\", (end2-end1)*1000, \"ms\")\n",
    "end3=time.time()\n",
    "degrees=np.degrees(asine)\n",
    "end=time.time()\n",
    "print(\"Time taken for element wise degree operations:\", (end-end3)*1000, \"ms\")\n",
    "print(\"total time taken for element wise operations:\", (end-start)*1000, \"ms\")\n",
    "# print(\"a sine:\", degrees)\n",
    "# print(\"ae:\", ae)\n",
    "# print(\"a:\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b159b5",
   "metadata": {},
   "source": [
    "## Lets Code for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f49119ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1, 100000)\n",
      "Y shape: (1, 100000)\n",
      "X: 0.37512684766943194 Y: 0\n"
     ]
    }
   ],
   "source": [
    "# Lets Genrate some data and pass thorugh a function and get a Output data\n",
    "# This data is out ground truth data and we want to tune our weights of LR model \n",
    "# TO predict the out of function.\n",
    "X=np.random.rand(1, 100000)\n",
    "# Here Input vector has only one element and There are 100000 such training examples.\n",
    "# nx=1 and m=100000\n",
    "print(\"X shape:\", X.shape)\n",
    "# We are going to use a function Y=2X+3>4 to generate the output data.\n",
    "# As this is LOGISTIC REGRESSION , Our output should be the binary value of 0 or 1.\n",
    "Y = ((2 * X + 3 )>4).astype(int)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "print(\"X:\", X[0][2],\"Y:\", Y[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4063314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[0.0124031]] B: -0.00018500000000000002\n",
      "Cost: 0.6931471805599453\n",
      "dW: [[-0.12403103]] dB: 0.00185\n",
      "X: 0.37512684766943194  Predicted : 0.5 Truth: 0\n",
      "-------------------------------\n",
      "W: [[0.98931572]] B: -0.3299833214077108\n",
      "Cost: 0.5840963428941714\n",
      "dW: [[-0.08408894]] dB: 0.041755578738047805\n",
      "X: 0.37512684766943194  Predicted : 0.5105376194988209 Truth: 0\n",
      "-------------------------------\n",
      "W: [[1.76162888]] B: -0.727672733948925\n",
      "Cost: 0.5083083020267528\n",
      "dW: [[-0.07139579]] dB: 0.0372003657339594\n",
      "X: 0.37512684766943194  Predicted : 0.4835567671291925 Truth: 0\n",
      "-------------------------------\n",
      "W: [[2.42645539]] B: -1.0735638361800146\n",
      "Cost: 0.45193166867123574\n",
      "dW: [[-0.06203832]] dB: 0.032199623827717405\n",
      "X: 0.37512684766943194  Predicted : 0.4594784323915578 Truth: 0\n",
      "-------------------------------\n",
      "W: [[3.00798894]] B: -1.3746742125886289\n",
      "Cost: 0.4089050572929383\n",
      "dW: [[-0.05462182]] dB: 0.02821893694002196\n",
      "X: 0.37512684766943194  Predicted : 0.4389255192978544 Truth: 0\n",
      "-------------------------------\n",
      "W: [[3.52311339]] B: -1.640318676604025\n",
      "Cost: 0.3752167112665535\n",
      "dW: [[-0.04867561]] dB: 0.025059603495413016\n",
      "X: 0.37512684766943194  Predicted : 0.4211573288827992 Truth: 0\n",
      "-------------------------------\n",
      "W: [[3.98469051]] B: -1.8776286706711347\n",
      "Cost: 0.3482125068072606\n",
      "dW: [[-0.04385061]] dB: 0.02251635635496791\n",
      "X: 0.37512684766943194  Predicted : 0.40558250752385383 Truth: 0\n",
      "-------------------------------\n",
      "W: [[4.40253771]] B: -2.091957785280961\n",
      "Cost: 0.3261109099266487\n",
      "dW: [[-0.03988335]] dB: 0.02043740520969552\n",
      "X: 0.37512684766943194  Predicted : 0.391764777648488 Truth: 0\n",
      "-------------------------------\n",
      "W: [[4.7841957]] B: -2.287365186764864\n",
      "Cost: 0.3076906622419347\n",
      "dW: [[-0.03657826]] dB: 0.018712996591109803\n",
      "X: 0.37512684766943194  Predicted : 0.3793787877539226 Truth: 0\n",
      "-------------------------------\n",
      "W: [[5.13551872]] B: -2.4669727122892287\n",
      "Cost: 0.2920951622802969\n",
      "dW: [[-0.03379049]] dB: 0.017263376721920402\n",
      "X: 0.37512684766943194  Predicted : 0.3681775795067788 Truth: 0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "W=0\n",
    "B=0\n",
    "for i in range(1000):\n",
    "    Z=np.dot(W, X) + B\n",
    "    A=1/(1+np.exp(-Z))\n",
    "    dZ= A-Y\n",
    "    dW= np.dot(X, dZ.T)/X.shape[1]\n",
    "    dB= np.sum(dZ)/X.shape[1]\n",
    "    W=W-0.1*dW\n",
    "    B=B-0.1*dB\n",
    "    if i%100==0:\n",
    "        print(\"W:\", W, \"B:\", B)\n",
    "        print(\"Cost:\", np.sum(-Y*np.log(A)-(1-Y)*np.log(1-A))/X.shape[1])\n",
    "        print(\"dW:\", dW, \"dB:\", dB)\n",
    "        print(\"X:\", X[0][2],\" Predicted :\", A[0][2], \"Truth:\", Y[0][2], )\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83702bd",
   "metadata": {},
   "source": [
    "In the Above Output you can notice That\n",
    "1. Cost function is reducing and If I increase the number of Iteration , It might decrese more\n",
    "2. Convergence also depends on the learning rate\n",
    "3. YOu can notice you predicted value comes closer to Truth value\n",
    "4. You can verify the Prediction by selecting any value of x between 0 and 1 and calculate  Z\n",
    "5. Post that pass z value to sigmoid function and get A value which is predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5d318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7172ec9d",
   "metadata": {},
   "source": [
    "### An Interesting Case Of logistic Regession where my model Needs to predict Odd/ Even Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "34dfba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1, 100000)\n",
      "Y shape: (1, 100000)\n"
     ]
    }
   ],
   "source": [
    "X=np.random.randint(-100, 100, (1, 100000))\n",
    "Y =  (X%2 == 0).astype(int)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d817f4",
   "metadata": {},
   "source": [
    "Here If I give only one feature that is random number from -100 to 100 and try to learn weights based on Output Y. It will converge to some other minima and I would not get accurate prediction. This is because Because \"evenness\" is not linearly separable.\n",
    "It can only solve problems where you can separate class 0 and class 1 with a straight line (in 1D or higher dimensions).\n",
    "The label alternates every step, like a wave.\n",
    "\n",
    "There is no linear boundary that separates this alternating pattern.\n",
    "\n",
    "So Logistic Regression can't learn this rule.\n",
    "\n",
    "Hence I am introducing another feature here which says if the number is divisible by 2 or not.\n",
    "This would be exactly same as the Output vector Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e150518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2, 1, 100000)\n",
      "X shape: (2, 100000)\n"
     ]
    }
   ],
   "source": [
    "X1=np.array([X,Y])\n",
    "print(\"X shape:\", X1.shape)\n",
    "X1=np.reshape(X1, (2, 100000))\n",
    "print(\"X shape:\", X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8333d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "W=np.zeros((2, 1))\n",
    "print(\"W shape:\", W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc5474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[-0.0041617]\n",
      " [ 0.0024996]] B: -8.000000000000001e-07\n",
      "Cost: 0.6931471805599453\n",
      "dW: [[ 0.41617]\n",
      " [-0.24996]] dB: 8e-05\n",
      "X1: 35 X2: 0  Predicted : 0.5 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-0.14449438]\n",
      " [ 2.26111936]] B: -0.22458265297990895\n",
      "Cost: 1.9913088556299128\n",
      "dW: [[23.96741817]\n",
      " [-0.20010967]] dB: 0.04506194269634702\n",
      "X1: 35 X2: 0  Predicted : 0.9571871590156502 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-0.12950854]\n",
      " [ 4.15832051]] B: -0.7285272924962131\n",
      "Cost: 1.790307979666968\n",
      "dW: [[23.21801324]\n",
      " [-0.17012361]] dB: 0.06326704896878918\n",
      "X1: 35 X2: 0  Predicted : 0.9461200537632105 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-0.11874201]\n",
      " [ 5.78259714]] B: -1.3739248563274924\n",
      "Cost: 1.4955979478800838\n",
      "dW: [[22.16743462]\n",
      " [-0.14657754]] dB: 0.07126099998071171\n",
      "X1: 35 X2: 0  Predicted : 0.9028604732387896 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-0.10876032]\n",
      " [ 7.17230314]] B: -2.0827543094097547\n",
      "Cost: 1.1698263289908724\n",
      "dW: [[20.77199133]\n",
      " [-0.1251791 ]] dB: 0.07347108948361775\n",
      "X1: 35 X2: 0  Predicted : 0.7992424285088736 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-0.09602106]\n",
      " [ 8.33068815]] B: -2.80585731510741\n",
      "Cost: 0.8124813118327808\n",
      "dW: [[18.62243919]\n",
      " [-0.10112397]] dB: 0.07240485795929565\n",
      "X1: 35 X2: 0  Predicted : 0.5870984605322142 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-1.53564444e-04]\n",
      " [ 8.78989458e+00]] B: -3.250873813572985\n",
      "Cost: 0.020970489927934027\n",
      "dW: [[ 5.83503937e-07]\n",
      " [-1.95659494e-03]] dB: 0.016696645417525663\n",
      "X1: 35 X2: 0  Predicted : 0.0371089746738121 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-1.59580788e-04]\n",
      " [ 8.81085131e+00]] B: -3.403003447054826\n",
      "Cost: 0.018604918419436154\n",
      "dW: [[ 6.13234214e-07]\n",
      " [-2.22967661e-03]] dB: 0.013875513993166756\n",
      "X1: 35 X2: 0  Predicted : 0.03203242853244276 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-1.65721391e-04]\n",
      " [ 8.83439209e+00]] B: -3.530680128658635\n",
      "Cost: 0.016915186429883336\n",
      "dW: [[ 6.10483204e-07]\n",
      " [-2.47322313e-03]] dB: 0.011756214385914324\n",
      "X1: 35 X2: 0  Predicted : 0.028295125053657874 Truth: 0\n",
      "-------------------------------\n",
      "W: [[-1.71718998e-04]\n",
      " [ 8.86021741e+00]] B: -3.6396789668997904\n",
      "Cost: 0.015657865793542905\n",
      "dW: [[ 5.86250434e-07]\n",
      " [-2.68661242e-03]] dB: 0.010110783657819887\n",
      "X1: 35 X2: 0  Predicted : 0.025441872663255205 Truth: 0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "W=np.zeros((2, 1)) # Column vector\n",
    "B=0\n",
    "for i in range(10000):\n",
    "    Z=np.dot(W.T, X1) + B # Row Vector [1,10000]\n",
    "    A=1/(1+np.exp(-Z))# Row Vector [1,10000]\n",
    "    dZ= A-Y # Row Vector [1,10000]\n",
    "    dW= np.dot(X1, dZ.T)/X1.shape[1] # Column Vector [2,1]\n",
    "    dB= np.sum(dZ)/X1.shape[1] # Scalar\n",
    "    W=W-0.01*dW # Column Vector [2,1]\n",
    "    B=B-0.01*dB # Scalar\n",
    "    if i%1000==0:\n",
    "        print(\"W:\", W, \"B:\", B)\n",
    "        print(\"Cost:\", np.sum(-Y*np.log(A)-(1-Y)*np.log(1-A))/X1.shape[1])\n",
    "        print(\"dW:\", dW, \"dB:\", dB)\n",
    "        print(\"X1:\", X1[0][2], \"X2:\", X1[1][2],\" Predicted :\", A[0][2], \"Truth:\", Y[0][2], )\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951690c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (2, 9)\n",
      "X1: 1 X2: 0  Predicted : 0.023337328979371595 Truth: 0\n",
      "X1: 2 X2: 1  Predicted : 0.9942554016800846 Truth: 1\n",
      "X1: 44 X2: 1  Predicted : 0.9942126893133956 Truth: 1\n",
      "X1: 55 X2: 0  Predicted : 0.0231199817420958 Truth: 0\n",
      "X1: -12 X2: 1  Predicted : 0.9942695693732415 Truth: 1\n",
      "X1: -24 X2: 1  Predicted : 0.9942816854565367 Truth: 1\n",
      "X1: 35 X2: 0  Predicted : 0.02320024931934821 Truth: 0\n",
      "X1: 99 X2: 0  Predicted : 0.02294434631957597 Truth: 0\n",
      "X1: -98 X2: 1  Predicted : 0.9943558404858729 Truth: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From the Above output we can see that the model is learning and the cost is decreasing.\n",
    "# Now we can use the learned weights and bias to predict the output for new data.\n",
    "# Testimg the model on new data\n",
    "X_test=np.array([[1,2,44,55,-12,-24,35,99,-98], [0,1,1,0,1,1,0,0,1]])\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "Z_test=np.dot(W.T, X_test) + B # Row Vector [1,10000]\n",
    "A_test=1/(1+np.exp(-Z_test))# Row Vector [1,10000]\n",
    "for i in range(X_test.shape[1]):\n",
    "    print(\"X1:\", X_test[0][i], \"X2:\", X_test[1][i],\" Predicted :\", A_test[0][i], \"Truth:\", X_test[1][i], )\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d6792",
   "metadata": {},
   "source": [
    "Yes Now Its Possible to get the the Odd/Even Classification using Logistic regression\n",
    "In the Above output you can see All Odd numbers are predicted with 0.99 and all even number are predicted with 0.02 probablility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6172a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
